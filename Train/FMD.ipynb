{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "FMD",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LybuQvf2w8QZ"
      },
      "source": [
        "import os\n",
        "from os import path\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense,Dropout\n",
        "from keras.models import Model, load_model\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "IMG_ROWS = 112\n",
        "IMG_COLS = 112\n",
        "num_classes = 2\n",
        "batch_size = 32\n",
        "# Grayscale Images 1\n",
        "# Colored Images 3\n",
        "channel_type = 1 \n",
        "activation_type = \"relu\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGSwPDIrxYMS"
      },
      "source": [
        "\n",
        "\n",
        "layers = [\n",
        "          Conv2D(64, (3,3), input_shape=(IMG_ROWS, IMG_COLS, channel_type)),\n",
        "          Activation(activation_type),\n",
        "          MaxPooling2D(pool_size=(2,2)),\n",
        "          Conv2D(128, (3,3)),\n",
        "          Activation(activation_type),\n",
        "          MaxPooling2D(pool_size=(2,2)),\n",
        "          Flatten(),\n",
        "          Dropout(0.5),\n",
        "          Dense(64, activation=activation_type),\n",
        "          Dense(num_classes, activation='softmax')\n",
        "]\n",
        "model = Sequential(layers)\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = Adam(lr=0.001),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5fCcyIm1k49"
      },
      "source": [
        "# Load the Dataset\n",
        "os.chdir('/content/drive/My Drive/Datasets')\n",
        "dataset = 'FaceMaskDataset'\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "data_categories = os.listdir(dataset)\n",
        "\n",
        "for ctg in data_categories:\n",
        "  print(f'\\n[READING] {ctg}')\n",
        "  active_ctg = path.join(dataset, ctg)\n",
        "\n",
        "  for img in os.listdir(active_ctg):\n",
        "    print('\\r',f'[CURRENT] {img}', end=' ')\n",
        "    img = cv2.imread(path.join(active_ctg, img))\n",
        "    try:\n",
        "      img_greyscaled = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "      images.append(\n",
        "          cv2.resize(img_greyscaled, (IMG_ROWS, IMG_COLS))\n",
        "      )\n",
        "      labels.append(ctg)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "print(\"[DONE] Images read successfully\")\n",
        "    \n",
        "images = np.array(images)/255.0\n",
        "images = np.reshape(images, (\n",
        "    images.shape[0], IMG_ROWS, IMG_COLS, 1\n",
        ")) \n",
        "# Hot encode labels because they are in textual form\n",
        "lb_binarizer = LabelBinarizer()\n",
        "labels = lb_binarizer.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "labels = np.array(labels)\n",
        "\n",
        "(train_x, test_x, train_y, test_y) = train_test_split(\n",
        "    images, labels, test_size=0.25, random_state=0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVvaZRaexxog"
      },
      "source": [
        "fitted_fmd_model = model.fit(\n",
        "    train_x,\n",
        "    train_y,\n",
        "    epochs = 50,\n",
        "    validation_split = 0.25\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8bEk1uYLcFO"
      },
      "source": [
        "# Plotting \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Tranning and Validation Loss\n",
        "plt.plot(fitted_fmd_model.history['loss'],'r',label='Tranning Loss')\n",
        "plt.plot(fitted_fmd_model.history['val_loss'],label='Validation Loss')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig(\"TranningValidationLoss.png\")\n",
        "\n",
        "\n",
        "# Tranning and Validation Accuracy\n",
        "plt.plot(fitted_fmd_model.history['accuracy'],'r',label='Tranning Accuracy')\n",
        "plt.plot(fitted_fmd_model.history['val_accuracy'],label='Validation Accuracy')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy Value')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig(\"TranningValidationAccuracy.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy9chFLLMK2l"
      },
      "source": [
        "model.save('FMDM.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGi0zTMQtRjs"
      },
      "source": [
        "# Install opencv [FOR GOOGLE COLAB]\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fcMEygFvx_9"
      },
      "source": [
        "# To Take input from webcam on Google Colab\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPjtLXCNYCK3"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Datasets')\n",
        "\n",
        "m = load_model('FMDM.h5')\n",
        "c = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "video = cv2.VideoCapture(0)\n",
        "results = {\n",
        "    0 : 'Wearing Mask',\n",
        "    1 : 'No Mask' \n",
        "}\n",
        "\n",
        "colors = {\n",
        "    0 : (0,255,0),\n",
        "    1 : (0,0,255)\n",
        "}\n",
        "\n",
        "while True:\n",
        "  # ret, img = video.read()\n",
        "  img = cv2.imread(take_photo(), cv2.IMREAD_UNCHANGED)\n",
        "  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  faces = c.detectMultiScale(img_gray, 1.3, 5)\n",
        "\n",
        "  for (x,y,w,h) in faces:\n",
        "    img_face = img_gray[y:y+w, x:x+w]\n",
        "    img_norm = cv2.resize(img_face, (112,112)) / 255.0\n",
        "    img_rshp = np.reshape(img_norm, (1,112,112,1))\n",
        "\n",
        "    r = m.predict(img_rshp)\n",
        "    l = np.argmax(r, axis=1)[0]\n",
        "\n",
        "    print(l)\n",
        "\n",
        "    cv2.rectangle(img, (x, y), (x + w, y + h), colors[l],2)\n",
        "    cv2.rectangle(img, (x, y - 40), (x + w, y),colors[l], -1)\n",
        "    cv2.putText(img, results[l], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
        "  # cv2.imshow() causes jupyter session problems on Colab, so using Google Patch\n",
        "  cv2_imshow(img)\n",
        "  k = cv2.waitKey(1)\n",
        "  if k == 27:\n",
        "    break\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}